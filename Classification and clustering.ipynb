{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0   Feb                 1   \n",
       "1         0.00       0.10         0.0         0.0   Feb                 2   \n",
       "2         0.20       0.20         0.0         0.0   Feb                 4   \n",
       "3         0.05       0.14         0.0         0.0   Feb                 3   \n",
       "4         0.02       0.05         0.0         0.0   Feb                 3   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  \n",
       "3        2       2            4  Returning_Visitor    False    False  \n",
       "4        3       1            4  Returning_Visitor     True    False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Classification=pd.read_csv(r'C:\\Users\\sandy\\Desktop\\Project_realected_practice\\Online_shoppers_purchasing\\online+shoppers+purchasing+intention+dataset\\online_shoppers_intention.csv')\n",
    "Classification.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12330, 18)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Returning_Visitor', 'New_Visitor', 'Other'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification['VisitorType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Feb', 'Mar', 'May', 'Oct', 'June', 'Jul', 'Aug', 'Nov', 'Sep',\n",
       "       'Dec'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification['Month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 18, 19,\n",
       "       16, 17, 20])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification['TrafficType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification['Revenue'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification['Weekend'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 column in categorical values need to be do a encoding to change it into a numerical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1]\n",
      "[0 1]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Import label encoder \n",
    "from sklearn import preprocessing \n",
    "a=['VisitorType','Revenue','Weekend']\n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "for i in a:\n",
    "    Classification[i]= label_encoder.fit_transform(Classification[i]) \n",
    "    print(Classification[i].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so In visitor type 'Returning_Visitor'--> 2, 'New_Visitor'--> 0, 'Other'---> 1\n",
    "\n",
    "Similarly in Revenue False --> 0 True ---> 1\n",
    "\n",
    "In Weekend False --> 0 True ---> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now need to map Month since there the mounth is not arranged regularly I am using the map to have a control of which month have which number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay  Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0      2                 1   \n",
       "1         0.00       0.10         0.0         0.0      2                 2   \n",
       "2         0.20       0.20         0.0         0.0      2                 4   \n",
       "3         0.05       0.14         0.0         0.0      2                 3   \n",
       "4         0.02       0.05         0.0         0.0      2                 3   \n",
       "\n",
       "   Browser  Region  TrafficType  VisitorType  Weekend  Revenue  \n",
       "0        1       1            1            2        0        0  \n",
       "1        2       1            2            2        0        0  \n",
       "2        1       9            3            2        0        0  \n",
       "3        2       2            4            2        0        0  \n",
       "4        3       1            4            2        1        0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Classification.Month=Classification.Month.map({'Feb':2, 'Mar':3, 'May':5, 'Oct':10, 'June':6, 'Jul':7, 'Aug':8, 'Nov':9, 'Sep':11,'Dec':12})\n",
    "Classification.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperating the Features and Tragets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay  Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0      2                 1   \n",
       "1         0.00       0.10         0.0         0.0      2                 2   \n",
       "2         0.20       0.20         0.0         0.0      2                 4   \n",
       "3         0.05       0.14         0.0         0.0      2                 3   \n",
       "4         0.02       0.05         0.0         0.0      2                 3   \n",
       "\n",
       "   Browser  Region  TrafficType  Weekend  Revenue  \n",
       "0        1       1            1        0        0  \n",
       "1        2       1            2        0        0  \n",
       "2        1       9            3        0        0  \n",
       "3        2       2            4        0        0  \n",
       "4        3       1            4        1        0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Feature_1=Classification.drop('VisitorType',axis=1)\n",
    "Feature_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: VisitorType, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target=Classification['VisitorType']\n",
    "Target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the Features since it is a classification kind of problem no need for scale the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Standradization should be done after splitted the data in here I have mistakenly standadized before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.69699296, -0.4571914 , -0.3964779 , ..., -0.76262903,\n",
       "        -0.55055169, -0.42787179],\n",
       "       [-0.69699296, -0.4571914 , -0.3964779 , ..., -0.51418219,\n",
       "        -0.55055169, -0.42787179],\n",
       "       [-0.69699296, -0.4571914 , -0.3964779 , ..., -0.26573535,\n",
       "        -0.55055169, -0.42787179],\n",
       "       ...,\n",
       "       [-0.69699296, -0.4571914 , -0.3964779 , ...,  2.21873304,\n",
       "         1.81635987, -0.42787179],\n",
       "       [ 0.50722805, -0.03291592, -0.3964779 , ...,  1.72183936,\n",
       "        -0.55055169, -0.42787179],\n",
       "       [-0.69699296, -0.4571914 , -0.3964779 , ..., -0.51418219,\n",
       "         1.81635987, -0.42787179]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "Feature = scaler.fit_transform(Feature_1)\n",
    "Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting the Data for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Feature, Target, test_size=0.3, random_state=10,stratify=Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisitorType\n",
       "2    3165\n",
       "0     508\n",
       "1      26\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisitorType\n",
       "2    7386\n",
       "0    1186\n",
       "1      59\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now training the LogisticRegression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.858610435252771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.09      0.16       508\n",
      "           1       0.79      0.58      0.67        26\n",
      "           2       0.87      0.98      0.92      3165\n",
      "\n",
      "    accuracy                           0.86      3699\n",
      "   macro avg       0.72      0.55      0.58      3699\n",
      "weighted avg       0.82      0.86      0.82      3699\n",
      "\n",
      "col_0         0   1     2\n",
      "VisitorType              \n",
      "0            47   0   461\n",
      "1             1  15    10\n",
      "2            47   4  3114\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Logi_model = LogisticRegression(max_iter=10000)\n",
    "Logi_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "Logi_model_pred = Logi_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, Logi_model_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Print the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, Logi_model_pred ))\n",
    "crosstab_result = pd.crosstab(y_test,Logi_model_pred )\n",
    "\n",
    "print(crosstab_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to increase the model acurracy means we want to drop the 0 - class since it have a less f1-score but I will leave it as it is and I will move to the next algorithm to check which algorithm gives a best accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN- K-Neareast Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of k-value 1 is 0.7961611246282779\n",
      "Accuracy score of k-value 1 is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.30      0.29       508\n",
      "           1       0.60      0.58      0.59        26\n",
      "           2       0.88      0.88      0.88      3165\n",
      "\n",
      "    accuracy                           0.80      3699\n",
      "   macro avg       0.59      0.58      0.59      3699\n",
      "weighted avg       0.80      0.80      0.80      3699\n",
      "\n",
      "Accuracy score of k-value 2 is 0.741551770748851\n",
      "Accuracy score of k-value 2 is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.47      0.34       508\n",
      "           1       0.47      0.62      0.53        26\n",
      "           2       0.90      0.79      0.84      3165\n",
      "\n",
      "    accuracy                           0.74      3699\n",
      "   macro avg       0.55      0.62      0.57      3699\n",
      "weighted avg       0.81      0.74      0.77      3699\n",
      "\n",
      "Accuracy score of k-value 3 is 0.8302243849689105\n",
      "Accuracy score of k-value 3 is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.24      0.29       508\n",
      "           1       0.94      0.58      0.71        26\n",
      "           2       0.88      0.93      0.90      3165\n",
      "\n",
      "    accuracy                           0.83      3699\n",
      "   macro avg       0.72      0.58      0.63      3699\n",
      "weighted avg       0.81      0.83      0.82      3699\n",
      "\n",
      "Accuracy score of k-value 4 is 0.8077858880778589\n",
      "Accuracy score of k-value 4 is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.35      0.34       508\n",
      "           1       0.88      0.58      0.70        26\n",
      "           2       0.89      0.88      0.89      3165\n",
      "\n",
      "    accuracy                           0.81      3699\n",
      "   macro avg       0.70      0.60      0.64      3699\n",
      "weighted avg       0.81      0.81      0.81      3699\n",
      "\n",
      "Accuracy score of k-value 5 is 0.8396864017301974\n",
      "Accuracy score of k-value 5 is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.22      0.27       508\n",
      "           1       0.88      0.58      0.70        26\n",
      "           2       0.88      0.94      0.91      3165\n",
      "\n",
      "    accuracy                           0.84      3699\n",
      "   macro avg       0.71      0.58      0.63      3699\n",
      "weighted avg       0.81      0.84      0.82      3699\n",
      "\n",
      "Accuracy score of k-value 6 is 0.8245471749121385\n",
      "Accuracy score of k-value 6 is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.26      0.30       508\n",
      "           1       0.94      0.58      0.71        26\n",
      "           2       0.88      0.92      0.90      3165\n",
      "\n",
      "    accuracy                           0.82      3699\n",
      "   macro avg       0.72      0.59      0.64      3699\n",
      "weighted avg       0.81      0.82      0.82      3699\n",
      "\n",
      "Accuracy score of k-value 7 is 0.8464449851311165\n",
      "Accuracy score of k-value 7 is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.16      0.23       508\n",
      "           1       0.94      0.58      0.71        26\n",
      "           2       0.87      0.96      0.91      3165\n",
      "\n",
      "    accuracy                           0.85      3699\n",
      "   macro avg       0.73      0.57      0.62      3699\n",
      "weighted avg       0.81      0.85      0.82      3699\n",
      "\n",
      "Accuracy score of k-value 8 is 0.8369829683698297\n",
      "Accuracy score of k-value 8 is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.21      0.27       508\n",
      "           1       0.94      0.58      0.71        26\n",
      "           2       0.88      0.94      0.91      3165\n",
      "\n",
      "    accuracy                           0.84      3699\n",
      "   macro avg       0.73      0.58      0.63      3699\n",
      "weighted avg       0.81      0.84      0.82      3699\n",
      "\n",
      "Accuracy score of k-value 9 is 0.8450932684509327\n",
      "Accuracy score of k-value 9 is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.14      0.20       508\n",
      "           1       0.94      0.58      0.71        26\n",
      "           2       0.87      0.96      0.91      3165\n",
      "\n",
      "    accuracy                           0.85      3699\n",
      "   macro avg       0.72      0.56      0.61      3699\n",
      "weighted avg       0.80      0.85      0.81      3699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "for k in range(1,10):\n",
    "    KNN_model = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\n",
    "    Knn_pred = KNN_model.predict(X_test)\n",
    "    final=accuracy_score(y_test, Knn_pred)\n",
    "    print(f'Accuracy score of k-value {k} is {final}')\n",
    "    final1=classification_report(y_test, Knn_pred)\n",
    "    print(f'Accuracy score of k-value {k} is {final1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this the best accuracy score is 84.6 which is achieved in k value k=7 when comparing with 7 nearseast neighbour it performs well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets go with Descion tree and random forest and check its accuracy score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.8318464449851312\n",
      "Accuracy score is               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.39      0.40       508\n",
      "           1       0.60      0.58      0.59        26\n",
      "           2       0.90      0.90      0.90      3165\n",
      "\n",
      "    accuracy                           0.83      3699\n",
      "   macro avg       0.63      0.62      0.63      3699\n",
      "weighted avg       0.83      0.83      0.83      3699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train,y_train)\n",
    "y_test_pred_DT = clf.predict(X_test)\n",
    "final=accuracy_score(y_test, y_test_pred_DT)\n",
    "print(f'Accuracy score is {final}')\n",
    "final1=classification_report(y_test, y_test_pred_DT)\n",
    "print(f'Accuracy score is {final1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can optimize this as well but let see how random forest and XGBoost works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with 100 decision-trees : 0.8746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.36      0.45       508\n",
      "           1       0.88      0.58      0.70        26\n",
      "           2       0.90      0.96      0.93      3165\n",
      "\n",
      "    accuracy                           0.87      3699\n",
      "   macro avg       0.79      0.63      0.69      3699\n",
      "weighted avg       0.86      0.87      0.86      3699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import Random Forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "Rfc = RandomForestClassifier(n_estimators=100,random_state=0)\n",
    "Rfc.fit(X_train, y_train)\n",
    "Rfc_ypred= Rfc.predict(X_test)\n",
    "\n",
    "print('Model accuracy score with 100 decision-trees : {0:0.4f}'. format(accuracy_score(y_test,Rfc_ypred)))\n",
    "print(classification_report(y_test,Rfc_ypred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "1080 fits failed out of a total of 3240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "407 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "673 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.87510126 0.87429014 0.87510133\n",
      " 0.87707114 0.87776632 0.87614394 0.87626008 0.87683959 0.87637609\n",
      " 0.87718755 0.87660791 0.87707094 0.87405913 0.87776632 0.87672371\n",
      " 0.87602867 0.87811448 0.87660764 0.87428994 0.8764919  0.87591272\n",
      " 0.87428994 0.8764919  0.87591272 0.87614387 0.87533342 0.87591252\n",
      " 0.87510126 0.87429014 0.87510133 0.87707114 0.87776632 0.87614394\n",
      " 0.87626008 0.87683959 0.87637609 0.87718755 0.87660791 0.87707094\n",
      " 0.87405913 0.87776632 0.87672371 0.87602867 0.87811448 0.87660764\n",
      " 0.87428994 0.8764919  0.87591272 0.87428994 0.8764919  0.87591272\n",
      " 0.87614387 0.87533342 0.87591252        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.87498593 0.87533382 0.87452263 0.87579692 0.87660791 0.87626008\n",
      " 0.87475364 0.87637596 0.87521741 0.87510173 0.87568118 0.87486965\n",
      " 0.87162616 0.87382751 0.87510167 0.87521761 0.87591313 0.87660797\n",
      " 0.8764919  0.87579698 0.87614441 0.8764919  0.87579698 0.87614441\n",
      " 0.87521727 0.87521741 0.87510207 0.87498593 0.87533382 0.87452263\n",
      " 0.87579692 0.87660791 0.87626008 0.87475364 0.87637596 0.87521741\n",
      " 0.87510173 0.87568118 0.87486965 0.87162616 0.87382751 0.87510167\n",
      " 0.87521761 0.87591313 0.87660797 0.8764919  0.87579698 0.87614441\n",
      " 0.8764919  0.87579698 0.87614441 0.87521727 0.87521741 0.87510207\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.87463777 0.87544876 0.87614441\n",
      " 0.87498559 0.87498552 0.87625988 0.87510113 0.87776652 0.8779982\n",
      " 0.87718701 0.87741843 0.8775345  0.87359529 0.8784615  0.87683919\n",
      " 0.8764925  0.87602893 0.87510153 0.87637528 0.87695526 0.87695553\n",
      " 0.87637528 0.87695526 0.87695553 0.87626015 0.87660797 0.87533342\n",
      " 0.87463777 0.87544876 0.87614441 0.87498559 0.87498552 0.87625988\n",
      " 0.87510113 0.87776652 0.8779982  0.87718701 0.87741843 0.8775345\n",
      " 0.87359529 0.8784615  0.87683919 0.8764925  0.87602893 0.87510153\n",
      " 0.87637528 0.87695526 0.87695553 0.87637528 0.87695526 0.87695553\n",
      " 0.87626015 0.87660797 0.87533342        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.87568064 0.87498546 0.87568064 0.87707114 0.87776632 0.87614387\n",
      " 0.87626008 0.87683959 0.87660784 0.87718755 0.87626028 0.87707094\n",
      " 0.87429088 0.87730282 0.87649196 0.87602867 0.87811448 0.87660764\n",
      " 0.87428994 0.8764919  0.87591272 0.87428994 0.8764919  0.87591272\n",
      " 0.87614387 0.87533342 0.87591252 0.87568064 0.87498546 0.87568064\n",
      " 0.87707114 0.87776632 0.87614387 0.87626008 0.87683959 0.87660784\n",
      " 0.87718755 0.87626028 0.87707094 0.87429088 0.87730282 0.87649196\n",
      " 0.87602867 0.87811448 0.87660764 0.87428994 0.8764919  0.87591272\n",
      " 0.87428994 0.8764919  0.87591272 0.87614387 0.87533342 0.87591252\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.87255249 0.87568104 0.8755653\n",
      " 0.87429034 0.8751014  0.87568077 0.87602846 0.87498512 0.8769552\n",
      " 0.87637642 0.87602826 0.87591232 0.87336388 0.87637575 0.87544909\n",
      " 0.87533301 0.87683912 0.87741843 0.87846137 0.87683986 0.87765085\n",
      " 0.87846137 0.87683986 0.87765085 0.87822948 0.87741869 0.87707087\n",
      " 0.87255249 0.87568104 0.8755653  0.87429034 0.8751014  0.87568077\n",
      " 0.87602846 0.87498512 0.8769552  0.87637642 0.87602826 0.87591232\n",
      " 0.87336388 0.87637575 0.87544909 0.87533301 0.87683912 0.87741843\n",
      " 0.87846137 0.87683986 0.87765085 0.87846137 0.87683986 0.87765085\n",
      " 0.87822948 0.87741869 0.87707087        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.87799847 0.87834563 0.8784619  0.87718741 0.8774191  0.87730342\n",
      " 0.87672358 0.87498613 0.87695573 0.87846143 0.87753444 0.8769554\n",
      " 0.87788253 0.87776645 0.87649223 0.87776692 0.87591299 0.87718735\n",
      " 0.87660797 0.87602867 0.87637663 0.87660797 0.87602867 0.87637663\n",
      " 0.87556503 0.87498579 0.87579672 0.87799847 0.87834563 0.8784619\n",
      " 0.87718741 0.8774191  0.87730342 0.87672358 0.87498613 0.87695573\n",
      " 0.87846143 0.87753444 0.8769554  0.87788253 0.87776645 0.87649223\n",
      " 0.87776692 0.87591299 0.87718735 0.87660797 0.87602867 0.87637663\n",
      " 0.87660797 0.87602867 0.87637663 0.87556503 0.87498579 0.87579672\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.87255282 0.8746377  0.87614434\n",
      " 0.87347915 0.87579638 0.87521748 0.8741742  0.87463777 0.87637602\n",
      " 0.87510106 0.87556456 0.87649156 0.87498519 0.87521694 0.87579651\n",
      " 0.87741876 0.87660764 0.87753497 0.87683905 0.87579678 0.87614414\n",
      " 0.87683905 0.87579678 0.87614414 0.87695439 0.87683905 0.8775341\n",
      " 0.87255282 0.8746377  0.87614434 0.87347915 0.87579638 0.87521748\n",
      " 0.8741742  0.87463777 0.87637602 0.87510106 0.87556456 0.87649156\n",
      " 0.87498519 0.87521694 0.87579651 0.87741876 0.87660764 0.87753497\n",
      " 0.87683905 0.87579678 0.87614414 0.87683905 0.87579678 0.87614414\n",
      " 0.87695439 0.87683905 0.8775341         nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.87197325 0.87394305 0.87556523 0.8732474  0.87568064 0.87579658\n",
      " 0.87626015 0.87498512 0.87672351 0.87626055 0.8755647  0.87649163\n",
      " 0.8735957  0.8755651  0.87544916 0.87533301 0.87707087 0.87765004\n",
      " 0.87846137 0.87718728 0.87788253 0.87846137 0.87718728 0.87788253\n",
      " 0.87822948 0.87753457 0.87695499 0.87197325 0.87394305 0.87556523\n",
      " 0.8732474  0.87568064 0.87579658 0.87626015 0.87498512 0.87672351\n",
      " 0.87626055 0.8755647  0.87649163 0.8735957  0.8755651  0.87544916\n",
      " 0.87533301 0.87707087 0.87765004 0.87846137 0.87718728 0.87788253\n",
      " 0.87846137 0.87718728 0.87788253 0.87822948 0.87753457 0.87695499]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'bootstrap': False, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Model accuracy score with best parameters: 0.8732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.31      0.40       508\n",
      "           1       0.94      0.58      0.71        26\n",
      "           2       0.89      0.97      0.93      3165\n",
      "\n",
      "    accuracy                           0.87      3699\n",
      "   macro avg       0.81      0.62      0.68      3699\n",
      "weighted avg       0.85      0.87      0.86      3699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define the Random Forest classifier\n",
    "rfc = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Define the hyperparameters and their corresponding values to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],         # Number of trees in the forest\n",
    "    'max_features': ['auto', 'sqrt', 'log2'], # Number of features to consider at every split\n",
    "    'max_depth': [None, 10, 20, 30],        # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],        # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],          # Minimum number of samples required at each leaf node\n",
    "    'bootstrap': [True, False]              # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the Random Forest classifier and the hyperparameters\n",
    "grid_search = GridSearchCV(estimator=rfc, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=5, \n",
    "                           n_jobs=-1, \n",
    "                           verbose=2, \n",
    "                           scoring='accuracy')\n",
    "\n",
    "# Fit GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters from Grid Search\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "# Use the best estimator to make predictions\n",
    "best_rfc = grid_search.best_estimator_\n",
    "y_pred = best_rfc.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Model accuracy score with best parameters: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with best parameters: 0.8732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.31      0.40       508\n",
      "           1       0.94      0.58      0.71        26\n",
      "           2       0.89      0.97      0.93      3165\n",
      "\n",
      "    accuracy                           0.87      3699\n",
      "   macro avg       0.81      0.62      0.68      3699\n",
      "weighted avg       0.85      0.87      0.86      3699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_rfc.predict(X_test)\n",
    "print('Model accuracy score with best parameters: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (2.0.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\sandy\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.14.0)\n",
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets Try with the XGBoost classifier algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:11:31] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with 100 estimators: 0.8751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.43      0.49       508\n",
      "           1       0.83      0.58      0.68        26\n",
      "           2       0.91      0.95      0.93      3165\n",
      "\n",
      "    accuracy                           0.88      3699\n",
      "   macro avg       0.77      0.65      0.70      3699\n",
      "weighted avg       0.86      0.88      0.87      3699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import XGBoost classifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = XGBClassifier(n_estimators=100, random_state=0, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Fit the model to the training data\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "xgb_ypred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Model accuracy score with 100 estimators: {0:0.4f}'.format(accuracy_score(y_test, xgb_ypred)))\n",
    "print(classification_report(y_test, xgb_ypred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have tried most of the classifier algorithm the maximum achievable accuracy is 87.5% in a XGBoost so I will keep it as it is and do a  optimization in decision and RandomForest by parameter tuning - Grid search CV let's try at what extent I can increase it accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will try with decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=8, min_samples_leaf=5, min_samples_split=4)\n",
      "Train score 0.8868033831537481\n",
      "Test score 0.851581508515815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "300 fits failed out of a total of 1500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "300 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeClassifier must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\sandy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan 0.85575251 0.85575251 0.85575251 0.85575251        nan\n",
      " 0.85575251 0.85575251 0.85575251 0.85575251        nan 0.85575251\n",
      " 0.85575251 0.85575251 0.85575251        nan 0.85575251 0.85575251\n",
      " 0.85575251 0.85575251        nan 0.85575251 0.85575251 0.85575251\n",
      " 0.85575251        nan 0.8561     0.8561     0.8561     0.8561\n",
      "        nan 0.8561     0.8561     0.8561     0.8561            nan\n",
      " 0.8561     0.8561     0.8561     0.8561            nan 0.8561\n",
      " 0.8561     0.8561     0.8561            nan 0.85586839 0.85586839\n",
      " 0.85586839 0.85586839        nan 0.85274118 0.85274118 0.85274118\n",
      " 0.85274118        nan 0.85274118 0.85274118 0.85274118 0.85274118\n",
      "        nan 0.85274118 0.85274118 0.85274118 0.85274118        nan\n",
      " 0.85274118 0.85274118 0.85274118 0.85274118        nan 0.85262537\n",
      " 0.85262537 0.85262537 0.85262537        nan 0.86050372 0.86050372\n",
      " 0.86050372 0.86050372        nan 0.86050372 0.86050372 0.86050372\n",
      " 0.86050372        nan 0.86050372 0.86050372 0.86050372 0.86050372\n",
      "        nan 0.86050372 0.86050372 0.86050372 0.86050372        nan\n",
      " 0.86061952 0.86061952 0.86061952 0.86061952        nan 0.86143098\n",
      " 0.86131511 0.86131511 0.86131511        nan 0.86131511 0.86131511\n",
      " 0.86131511 0.86131511        nan 0.86143098 0.86143098 0.86143098\n",
      " 0.86143098        nan 0.86085161 0.86085161 0.86085161 0.86085161\n",
      "        nan 0.86085161 0.86085161 0.86085161 0.86085161        nan\n",
      " 0.8631687  0.86270527 0.86316877 0.86374815        nan 0.8635164\n",
      " 0.86316877 0.86316884 0.86328471        nan 0.8636322  0.8636322\n",
      " 0.8636322  0.86374808        nan 0.86351633 0.8636322  0.86351633\n",
      " 0.86351633        nan 0.86374815 0.86421165 0.8639799  0.86409577\n",
      "        nan 0.86258886 0.86270474 0.86247292 0.86247299        nan\n",
      " 0.86143011 0.86154599 0.86143011 0.86154592        nan 0.86339972\n",
      " 0.86328384 0.86293622 0.86305209        nan 0.86386308 0.86386308\n",
      " 0.86386308 0.86374721        nan 0.8651377  0.86536945 0.86525358\n",
      " 0.8651377         nan 0.865486   0.8645588  0.86490663 0.86536999\n",
      "        nan 0.86386395 0.8635164  0.86455927 0.86340052        nan\n",
      " 0.86710811 0.86687636 0.86629699 0.86687636        nan 0.86722399\n",
      " 0.86710811 0.8668763  0.86710805        nan 0.86849848 0.86873023\n",
      " 0.8688461  0.86873023        nan 0.86154626 0.85992421 0.85957645\n",
      " 0.85853384        nan 0.86050392 0.86015616 0.86004035 0.85992441\n",
      "        nan 0.86351572 0.8631681  0.86328398 0.86351572        nan\n",
      " 0.86374747 0.86340005 0.86293648 0.8631683         nan 0.86733926\n",
      " 0.86780276 0.86745513 0.86826626        nan 0.85575211 0.85633155\n",
      " 0.85586792 0.85494092        nan 0.85470964 0.85447775 0.85517314\n",
      " 0.855173          nan 0.85899681 0.85946017 0.85911248 0.85969206\n",
      "        nan 0.86027103 0.8602713  0.86015522 0.85957611        nan\n",
      " 0.86444212 0.86374687 0.86351532 0.86467387        nan 0.85227687\n",
      " 0.8526249  0.85088671 0.85053888        nan 0.84949634 0.84938067\n",
      " 0.8503072  0.85019126        nan 0.85528989 0.85679592 0.85656431\n",
      " 0.85563731        nan 0.85598446 0.85494179 0.85586832 0.8556367\n",
      "        nan 0.8607352  0.86085107 0.86085094 0.86027163        nan\n",
      " 0.85192931 0.85123447 0.84856955 0.84914899        nan 0.84636846\n",
      " 0.84741167 0.84694757 0.8488015         nan 0.85459484 0.85482652\n",
      " 0.85378412 0.85540603        nan 0.85239301 0.85389932 0.85343569\n",
      " 0.85320427        nan 0.86154585 0.86212509 0.86061892 0.86061919]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "params = {'max_depth': [i for i in range(1,13)],\n",
    "        'min_samples_split': [i for i in range(1,6)],\n",
    "        'min_samples_leaf': [i for i in range(1,6)]}\n",
    "\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "gcv = GridSearchCV(estimator=clf,param_grid=params)\n",
    "gcv.fit(X_train,y_train)\n",
    "\n",
    "Optimized_DT = gcv.best_estimator_\n",
    "print(gcv.best_estimator_)\n",
    "Optimized_DT.fit(X_train,y_train)\n",
    "y_train_pred_Optim_DT = Optimized_DT.predict(X_train)\n",
    "y_test_pred_Optim_DT = Optimized_DT.predict(X_test)\n",
    "\n",
    "\n",
    "print(f'Train score {accuracy_score(y_train_pred_Optim_DT,y_train)}')\n",
    "print(f'Test score {accuracy_score(y_test_pred_Optim_DT,y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion is the XGBOOST model performs well in this its accuracy score is 87.5% so for further deployment I use this model and I will preserve this model for the future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Assuming your model is stored in a variable called 'model'\n",
    "with open('Shoppers_Class.pkl', 'wb') as file:\n",
    "   pickle.dump(xgb_model, file)\n",
    "\n",
    "\n",
    "with open('Shoppers_Class.pkl', 'rb') as file:\n",
    "   pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the same dataset for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering using Kmeans algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>627.500000</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "3               0                      0.0              0   \n",
       "4               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                 0.000000   \n",
       "1                     0.0               2                64.000000   \n",
       "2                     0.0               1                 0.000000   \n",
       "3                     0.0               2                 2.666667   \n",
       "4                     0.0              10               627.500000   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay  Month  OperatingSystems  \\\n",
       "0         0.20       0.20         0.0         0.0      2                 1   \n",
       "1         0.00       0.10         0.0         0.0      2                 2   \n",
       "2         0.20       0.20         0.0         0.0      2                 4   \n",
       "3         0.05       0.14         0.0         0.0      2                 3   \n",
       "4         0.02       0.05         0.0         0.0      2                 3   \n",
       "\n",
       "   Browser  Region  TrafficType  Weekend  Revenue  cluster  \n",
       "0        1       1            1        0        0        2  \n",
       "1        2       1            2        0        0        1  \n",
       "2        1       9            3        0        0        2  \n",
       "3        2       2            4        0        0        2  \n",
       "4        3       1            4        1        0        1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "algorithm = (KMeans(n_clusters = 3 ,init='k-means++', n_init = 10 ,max_iter=300,\n",
    "                       tol=0.0001,  random_state= 111  , algorithm='elkan') )\n",
    "algorithm.fit(Feature)\n",
    "\n",
    "y_kmeans = algorithm.fit_predict(Feature)\n",
    "Feature_1['cluster'] = pd.DataFrame(y_kmeans)\n",
    "Feature_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "1    9608\n",
       "0    1671\n",
       "2    1051\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Feature_1['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Assuming your model is stored in a variable called 'model'\n",
    "with open('Shoppers_Cluster.pkl', 'wb') as file:\n",
    "   pickle.dump(algorithm, file)\n",
    "\n",
    "\n",
    "with open('Shoppers_Cluster.pkl', 'rb') as file:\n",
    "   pickle.load(file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
